{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Optional, Callable, List, Dict, Tuple, Any\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/media/ana-caznok/SSD-08/recon-segment/\")\n",
    "sys.path.append(\"/media/ana-caznok/SSD-08/recon-segment/transforms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana-caznok/software/src/miniforge3/envs/agrvai/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transforms.factory import transform_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#27/11 \n",
    "class FixedDataset(Dataset):  \n",
    "    '''\n",
    "    Simply read data and apply a transform. \n",
    "    '''  \n",
    "    # TODO define 5 folds\n",
    "    VAL_LIST: List[str] = [\"p009\", \"p046\", \"p045\", \"p034\", \"p021\"]  # fold 0\n",
    "    def __init__(self, \n",
    "                 mode: str,\n",
    "                 base_path: str,\n",
    "                 transform: Optional[Callable] = None,  # real time processing\n",
    "                 preprocessing: Optional[str] = None, # pre-processing\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "  \n",
    "        for k, v in kwargs:\n",
    "            print(f\"WARNING: Ignoring dataset argument {k}: {v}\")\n",
    "\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.base_path = base_path\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "        if self.preprocessing == \"None\":\n",
    "            print(\"WARNING: interpreting None string as None type\")\n",
    "            self.preprocessing = None\n",
    "        \n",
    "        if self.preprocessing is None:\n",
    "            fmt = \"*.mat\"\n",
    "        elif self.preprocessing == \"downsampled\":\n",
    "            fmt = \"*.npy\"\n",
    "        elif self.preprocessing == \"h5py\":\n",
    "            print(\"Loading from hdf files\")\n",
    "            fmt = \"*.hdf\"\n",
    "            self.h5file_path = os.path.join(self.base_path, f\"{self.mode}.hdf\")\n",
    "            with h5py.File(self.h5file_path, 'r') as h5file:\n",
    "                self.keys = list(h5file.keys())\n",
    "            self.total_files = len(self.keys)\n",
    "\n",
    "        self.fmt = fmt\n",
    "\n",
    "        if mode != 'test':\n",
    "            if self.preprocessing != \"h5py\":\n",
    "                self.msi_files: List[str] = sorted(glob.glob(os.path.join(self.base_path, \"Hyper-Skin(MSI, NIR)\", \"train\", \"MSI_CIE\", fmt)))\n",
    "                self.vis_files: List[str] = sorted(glob.glob(os.path.join(self.base_path, \"Hyper-Skin(RGB, VIS)\", \"train\", \"VIS\", fmt)))\n",
    "                self.nir_files: List[str] = sorted(glob.glob(os.path.join(self.base_path, \"Hyper-Skin(MSI, NIR)\", \"train\", \"NIR\", fmt)))\n",
    "            \n",
    "                # Filter by fixed validation list and mode\n",
    "                self.msi_files = self.filter_files(self.msi_files)[mode]\n",
    "                self.vis_files = self.filter_files(self.vis_files)[mode]\n",
    "                self.nir_files = self.filter_files(self.nir_files)[mode]\n",
    "\n",
    "                self.total_files = len(self.msi_files)\n",
    "                assert len(self.msi_files) == len(self.vis_files) == len(self.nir_files) == self.total_files, f\"Length {self.total_files} is not matching among 3 folders\"\n",
    "            \n",
    "            # Temporarily removed, buggy\n",
    "            self.bb = []\n",
    "            self.bb_names = []\n",
    "            try:\n",
    "                self.bb_names, self.bb = self.read_BB(mode, downsample = self.preprocessing == \"downsampled\")\n",
    "            except FileNotFoundError as error:\n",
    "                print(f\"ERROR: Didn't found boundingbox files!: {error}\")\n",
    "                print(\"Continuinig without loading bounding boxes.\")\n",
    "            \n",
    "            self.mask_files: List[str] = sorted(glob.glob(os.path.join(self.base_path, \"masks_full_size_large-model\", '*.npy')))\n",
    "            self.mask_files = self.filter_files(self.mask_files)[mode]\n",
    "            nmasks = len(self.mask_files)\n",
    "            if nmasks != self.total_files:\n",
    "                raise ValueError(f\"Number of masks is not number of files...? {nmasks} / {self.total_files}\")\n",
    "            \n",
    "            print(f\"Number of face masks {len(self.mask_files)}.\", end=\" \")\n",
    "\n",
    "        if mode == \"test\":\n",
    "            fmt = '*.mat'\n",
    "            self.msi_files: List[str] = sorted(glob.glob(os.path.join(self.base_path, \"Hyper-Skin(MSI, NIR)\", \"test\", '*.mat')))\n",
    "            self.vis_files: List[str] = ['No_Target']*len(self.msi_files)\n",
    "            self.nir_files: List[str] = ['No_Target']*len(self.msi_files)\n",
    "            self.bb = ['No_BB']*len(self.msi_files)\n",
    "            self.total_files = len(self.msi_files)\n",
    "\n",
    "        print(self.init_str())\n",
    "\n",
    "    def init_str(self):\n",
    "        return f\"initialized {self.total_files} images {self.mode} DatasetRaw with preprocessing: {self.preprocessing} in {self.base_path} with transform {self.transform}\"\n",
    "\n",
    "    def load_masks(self, idx: int): \n",
    "        m_file = self.mask_files[idx]\n",
    "        \n",
    "        mask_ID = os.path.basename(m_file).replace(\"-mask.npy\", '')\n",
    "        mask = np.load(m_file)\n",
    "\n",
    "        # Workaround, downsamples face only in downsampled preprocessing or downsample of both input and target\n",
    "        if self.preprocessing == 'downsampled': \n",
    "            mask = mask[::4,::4]\n",
    "\n",
    "        return mask, mask_ID\n",
    "\n",
    "    def filter_files(self, files: List[str]) -> Dict[str, List[str]]:\n",
    "        val_files = []\n",
    "        train_files = []\n",
    "        for file in files:\n",
    "            val = False\n",
    "            for val_idx in FixedDataset.VAL_LIST:\n",
    "                if val_idx in file:\n",
    "                    val_files.append(file)\n",
    "                    val = True\n",
    "            \n",
    "            if not val:\n",
    "                train_files.append(file)\n",
    "        \n",
    "        return {\"train\": train_files, \"val\": val_files}\n",
    "\n",
    "    def loadCube(self, cube_path: str) -> np.ndarray:\n",
    "        '''\n",
    "        return cube channel first.\n",
    "        Original transpose: 2, 1, 0\n",
    "        Channel first, but keep face orientation: 0, 2, 1\n",
    "        intensity range: (0, 1)\n",
    "        '''\n",
    "        with h5py.File(cube_path, 'r') as f:\n",
    "            array: np.ndarray = f['cube'][:].transpose(0, 2, 1)  # correct face orientation and channel first\n",
    "            return array.squeeze()\n",
    "            \n",
    "    \n",
    "    def loadPreprocessing(self, path: str) -> np.ndarray:\n",
    "        return np.load(path)\n",
    "\n",
    "    def loadData(self, msi_path: str, vis_path: str, nir_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        '''\n",
    "        Convenção: remove first channel from NIR for 61 total channels (31 + (31 - 1))\n",
    "        '''\n",
    "        if self.preprocessing is None:\n",
    "            msi_input = self.loadCube(msi_path)\n",
    "            if self.mode != \"test\":\n",
    "                target = np.concatenate([self.loadCube(vis_path), self.loadCube(nir_path)[1:]], axis=0) #new, output 61\n",
    "            else:\n",
    "                target = \"None\"\n",
    "        elif self.preprocessing == \"downsampled\":\n",
    "            msi_input = self.loadPreprocessing(msi_path)\n",
    "            target = np.concatenate([self.loadPreprocessing(vis_path), self.loadPreprocessing(nir_path)[1:]], axis=0) #new, output 61\n",
    "\n",
    "        return msi_input, target \n",
    "    \n",
    "    def read_BB(self, r_mode: str, downsample: bool = True) -> Tuple[List[str], List[List[int]]]: \n",
    "        face_path = os.path.join(self.base_path, \"bounding-boxes/\")\n",
    "        file_name = 'faces_bb_NIR_w-rgb_BEST.json'\n",
    "      \n",
    "        mode_dict = {'train': True, \n",
    "                     'val': False}\n",
    "\n",
    "        with open(face_path + file_name) as json_file:\n",
    "            faceseg_BB = json.load(json_file)\n",
    "\n",
    "        key_array = np.asarray([k  for  k in  faceseg_BB.keys()])\n",
    "        values_array = np.asarray([np.asarray(v)  for  v in  faceseg_BB.values()])\n",
    "\n",
    "        name_list = []\n",
    "        for k in key_array: \n",
    "            name_list.append(k.split('_')[0])\n",
    "        \n",
    "        mask = np.isin(name_list, np.asarray(FixedDataset.VAL_LIST), invert=mode_dict[r_mode])\n",
    "\n",
    "        key_array = key_array[mask]\n",
    "        values_array = values_array[mask]\n",
    "        \n",
    "        if downsample == True: \n",
    "            values_array = values_array//4\n",
    "\n",
    "        return key_array, values_array\n",
    "\n",
    "    def load_h5(self, idx: int) -> Tuple[np.ndarray, np.ndarray, str]: #TODO ainda falta arrumar output 61 para leitura h5, ainda não entendi como foi feito\n",
    "        ID = self.keys[idx]\n",
    "        with h5py.File(self.h5file_path, 'r') as h5file:\n",
    "            # 31 canais, index 0 30\n",
    "            vis = h5file[ID][4:4 + 31] # indices 4 ate 34 incluidos\n",
    "            nir = h5file[ID][4 + 31 + 1:]  # skip first channel from nir, indices 36 ate o fim incluidos\n",
    "            msi_input = h5file[ID][:4]  # indices 0 a 3\n",
    "            target = np.concatenate((vis, nir), axis=0)\n",
    "\n",
    "        return msi_input, target, ID\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, Dict[str, Any]]:\n",
    "        # Read preprocessed or raw\n",
    "        if self.preprocessing == \"h5py\":\n",
    "            msi_input, target, ID = self.load_h5(idx)\n",
    "        else:\n",
    "            msi_input, target = self.loadData(self.msi_files[idx], self.vis_files[idx], self.nir_files[idx])\n",
    "            ID = os.path.basename(self.msi_files[idx]).replace(self.fmt[1:], '')\n",
    "        \n",
    "        try:\n",
    "            mask_input, mask_ID = self.load_masks(idx)\n",
    "            mask_input = np.expand_dims(mask_input, 0) \n",
    "        except: \n",
    "            mask_input = \"None\"\n",
    "            mask_ID = None\n",
    "\n",
    "        if mask_ID is not None:\n",
    "            assert mask_ID == ID, f\"Mask is not the same as person: {mask_ID} / {ID}\"\n",
    "\n",
    "        try:\n",
    "            img_bb = self.bb[idx]\n",
    "        except IndexError:\n",
    "            img_bb = \"None\"\n",
    "        \n",
    "        metadata = {\"ID\": ID, \"bbox\": img_bb, \"mask\": mask_input}\n",
    "\n",
    "        if self.transform is not None:\n",
    "            msi_input, target, metadata = self.transform(msi_input, target, metadata)\n",
    "\n",
    "        # Torch conversion is not in transforms from transform_factory\n",
    "        msi_input = torch.from_numpy(msi_input).float()\n",
    "        \n",
    "        # Target might be \"None\" in test\n",
    "        if not isinstance(target, str):\n",
    "            target = torch.from_numpy(target).float()\n",
    "\n",
    "        if mask_ID is not None:\n",
    "            metadata[\"mask\"] = torch.from_numpy(metadata[\"mask\"]).float()\n",
    "\n",
    "        return msi_input, target, metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path_ana = os.getenv(\"ICASP_DOWNSAMPLED\")\n",
    "#base_path_ana= '/mnt/datassd/icasp/data/preprocessed/downsampled'\n",
    "#preprocessing = \"downsampled\"\n",
    "\n",
    "#base_path_ana= '/mnt/datassd/icasp/data/raw/Link_2/'\n",
    "#preprocessing = None\n",
    "\n",
    "base_path_ana=  os.getenv('ICASP_H5')\n",
    "preprocessing = 'h5py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"ICASP_DOWNSAMPLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check repeated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = transform_factory('stft_D40_x_gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from hdf files\n",
      "Number of face masks 234. initialized 234 images train DatasetRaw with preprocessing: h5py in /media/ana-caznok/SSD-08/icasp_4090/icasp/data/Link_2 with transform \n",
      "0: Downsample by a factor of 4\n",
      "1: RGB2Pseudo_Hyp with: /media/ana-caznok/SSD-08/recon-segment/ and camera D40\n",
      "2: Spectrogram4D_ChannelFirst(F=32, T=?, norm=abs)\n"
     ]
    }
   ],
   "source": [
    "dataset = FixedDataset(\"train\", '/media/ana-caznok/SSD-08/icasp_4090/icasp/data/Link_2', preprocessing='h5py', transform=my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, m = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_diffs = [torch.abs((y[i] - y[i+1]).sum()).item() for i in range(y.shape[0] - 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(diffs, '*')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(new_diffs, '*')\n",
    "plt.figure()\n",
    "plt.plot(np.array(diffs[:-1]) - np.array(new_diffs))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(new_diffs).min(), np.array(new_diffs).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fixed_dataset import FixedDataset as NewFixedDataset\n",
    "dataset_new_h5 = NewFixedDataset(\"train\", os.getenv(\"ICASP\"), preprocessing=\"h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new_h5.h5file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, m = dataset_new_h5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fixed_dataset import FixedDataseabst as NewFixedDataset\n",
    "dataset_new_h5 = NewFixedDataset(\"train\", os.getenv(\"ICASP\"), preprocessing=\"h5py\")\n",
    "raw_dataset = NewFixedDataset(\"train\", os.getenv(\"ICASP\"), preprocessing=None)\n",
    "x, y, m = dataset_new_h5[0]\n",
    "rx, ry, rm = raw_dataset[0]\n",
    "print(f\"raw: {ry.shape}, h5: {y.shape}\")\n",
    "h5_diffs = [torch.abs((y[i] - y[i+1]).sum()).item() for i in range(60)]\n",
    "raw_diffs = [torch.abs((ry[i] - ry[i+1]).sum()).item() for i in range(60)]\n",
    "plt.plot(h5_diffs, label=\"H5\")\n",
    "plt.plot(raw_diffs, label=\"Raw\")\n",
    "plt.plot(np.array(h5_diffs) - np.array(raw_diffs), label=\"Subtract\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = transform_factory('hist_match_h5_04_and_patch_512')\n",
    "str(my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FixedDataset(mode = 'train', base_path=base_path_ana, preprocessing=preprocessing, transform = my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.total_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "x, y, m = random.choice(dataset)\n",
    "x_np = x.numpy()\n",
    "\n",
    "plt.imshow(x_np[30],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_debug = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, m = next(dataloader_debug)\n",
    "\n",
    "plt.imshow(make_grid(x[:, :3]).permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm(dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/datassd/icasp/RainbowAI/models_h5/mst_face_test_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.load(sorted(glob.glob(path+'*.npy'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agrvai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
